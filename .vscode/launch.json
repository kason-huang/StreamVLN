{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Python: 当前文件",
      "type": "python",
      "request": "launch",
      "program": "${file}",
      "console": "integratedTerminal",
      "justMyCode": false, 
      "env": {
          "PYTHONPATH": "${workspaceFolder}"
      }
    },
    {
        "name": "torchrun: Train StreamVLN finetune (4 GPUs)",
        "type": "python",
        "request": "launch",
        // 关键点：用模块方式启动 torchrun
        "module": "torch.distributed.run",
        // 把 torchrun 的参数 + 你原本脚本参数都放到 args
        "args": [
            "--nnodes=1",
            "--nproc_per_node=2",
            "--rdzv_id=12345",
            "--rdzv_backend=c10d",
            "--rdzv_endpoint=127.0.0.1:12000",
            "${workspaceFolder}/streamvln/streamvln_train.py",
            "--deepspeed", "${workspaceFolder}/scripts/zero2.json",
            "--model_name_or_path", "checkpoints/lmms-lab/LLaVA-Video-7B-Qwen2",
            "--version", "qwen_1_5",
            "--video_folder", "data/trajectory_data/R2R,data/trajectory_data/RxR_new",
            "--group_by_task", "False",
            "--num_history", "8",
            "--num_future_steps", "4",
            "--num_frames", "32",
            "--data_augmentation", "True",
            "--mm_tunable_parts", "mm_vision_tower,mm_mlp_adapter,mm_language_model",
            "--vision_tower", "google/siglip-so400m-patch14-384",
            "--mm_projector_type", "mlp2x_gelu",
            "--mm_vision_select_layer", "-2",
            "--mm_use_im_start_end", "False",
            "--mm_use_im_patch_token", "False",
            "--image_aspect_ratio", "anyres_max_9",
            "--image_grid_pinpoints", "(1x1),...,(6x6)",
            "--bf16", "True",
            "--run_name", "StreamVLN_Video_qwen_1_5_1epoch_196token_8history_32frame",
            "--output_dir", "checkpoints/StreamVLN_Video_qwen_1_5_1epoch_196token_8history_32frame",
            "--num_train_epochs", "1",
            "--per_device_train_batch_size", "1",
            "--per_device_eval_batch_size", "4",
            "--gradient_accumulation_steps", "32",
            "--evaluation_strategy", "no",
            "--save_strategy", "steps",
            "--save_steps", "10000",
            "--save_total_limit", "1",
            "--learning_rate", "2e-5",
            "--mm_vision_tower_lr", "5e-6",
            "--weight_decay", "0.",
            "--warmup_ratio", "0.075",
            "--lr_scheduler_type", "cosine_with_min_lr",
            "--lr_scheduler_kwargs", "{\"min_lr\": 1.85e-05}",
            "--logging_steps", "1",
            "--tf32", "False",
            "--model_max_length", "32768",
            "--gradient_checkpointing", "True",
            "--dataloader_num_workers", "8",
            "--lazy_preprocess", "True",
            "--torch_compile", "True",
            "--torch_compile_backend", "inductor",
            "--dataloader_drop_last", "True",
            "--report_to", "tensorboard"
        ],
        "console": "integratedTerminal",
        "subProcess": true,
        "justMyCode": false,
        "redirectOutput": true,
        "env": {
            "HF_HUB_OFFLINE": "1",
            "HF_HOME": "${workspaceFolder}/checkpoints/hf_home/",
            "PYTORCH_CUDA_ALLOC_CONF": "max_split_size_mb:128,garbage_collection_threshold:0.6",
            "NCCL_IB_DISABLE": "1",
            "NCCL_P2P_DISABLE": "1",
            "NCCL_DEBUG": "INFO",
            "NNODES": "1",
            "NPROC_PER_NODE": "2",
            "TORCH_DISTRIBUTED_DEBUG": "DETAIL",
            "MASTER_ADDR": "127.0.0.1",
            "MASTER_PORT": "12000",
            "PYTHONPATH": "${workspaceFolder}"
        },
        "cwd": "${workspaceFolder}"
    },{
        "name": "torchrun: Train StreamVLN finetune All (4 GPUs)",
        "type": "python",
        "request": "launch",
        // 关键点：用模块方式启动 torchrun
        "module": "torch.distributed.run",
        // 把 torchrun 的参数 + 你原本脚本参数都放到 args
        "args": [
            "--nnodes=1",
            "--nproc_per_node=4",
            // "--rdzv_id=12345",
            // "--rdzv_backend=c10d",
            // "--rdzv_endpoint=127.0.0.1:12000",
            "--standalone",
            "${workspaceFolder}/streamvln/streamvln_train.py",
            "--deepspeed", "${workspaceFolder}/scripts/zero2.json",
            "--model_name_or_path", "checkpoints/lmms-lab/LLaVA-Video-7B-Qwen2",
            "--version", "qwen_1_5",
            // "--objnav_video_folder", "data/test_object_datasets",
            // // "--video_folder", "data/test_object_datasets",
            "--video_folder", "data/trajectory_data/R2R_small_1118",
            "--group_by_task", "False",
            "--num_history", "8",
            "--num_future_steps", "4",
            "--num_frames", "32",
            "--data_augmentation", "True",
            "--mm_tunable_parts", "mm_vision_tower,mm_mlp_adapter,mm_language_model",
            "--vision_tower", "google/siglip-so400m-patch14-384",
            "--mm_projector_type", "mlp2x_gelu",
            "--mm_vision_select_layer", "-2",
            "--mm_use_im_start_end", "False",
            "--mm_use_im_patch_token", "False",
            "--image_aspect_ratio", "anyres_max_9",
            "--image_grid_pinpoints", "(1x1),...,(6x6)",
            "--fp16", "True",
            "--run_name", "StreamVLN_Video_qwen_1_5_1epoch_196token_8history_32frame",
            "--output_dir", "checkpoints/StreamVLN_Video_qwen_1_5_1epoch_196token_8history_32frame",
            "--num_train_epochs", "1",
            "--per_device_train_batch_size", "1",
            "--per_device_eval_batch_size", "4",
            "--gradient_accumulation_steps", "2",
            "--evaluation_strategy", "no",
            "--save_strategy", "steps",
            "--save_steps", "10",
            "--save_total_limit", "2",
            "--learning_rate", "2e-5",
            "--mm_vision_tower_lr", "5e-6",
            "--weight_decay", "0.",
            "--warmup_ratio", "0.075",
            "--lr_scheduler_type", "cosine_with_min_lr",
            "--lr_scheduler_kwargs", "{\"min_lr\": 1.85e-05}",
            "--logging_steps", "1",
            "--tf32", "True",
            "--model_max_length", "32768",
            "--gradient_checkpointing", "True",
            "--dataloader_num_workers", "8",
            "--lazy_preprocess", "True",
            "--torch_compile", "False",
            "--torch_compile_backend", "inductor",
            "--dataloader_drop_last", "True",
            "--report_to", "tensorboard"
        ],
        "console": "integratedTerminal",
        "subProcess": true,
        "justMyCode": false,
        "redirectOutput": true,
        "env": {
            "HF_HUB_OFFLINE": "1",
            "HF_HOME": "${workspaceFolder}/checkpoints/hf_home/",
            "PYTORCH_CUDA_ALLOC_CONF": "max_split_size_mb:128,garbage_collection_threshold:0.6",
            "NCCL_IB_DISABLE": "1",
            "NCCL_P2P_DISABLE": "1",
            "NCCL_DEBUG": "INFO",
            "NNODES": "1",
            "NPROC_PER_NODE": "2",
            "TORCH_DISTRIBUTED_DEBUG": "DETAIL",
            "MASTER_ADDR": "127.0.0.1",
            "MASTER_PORT": "12000",
            "PYTHONPATH": "${workspaceFolder}",
            "NCCL_NVLS_ENABLE": "0"
        },
        "cwd": "${workspaceFolder}"
    }
]
}