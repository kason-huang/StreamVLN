#!/usr/bin/env python3
"""
ä»data1/trajectory_data/R2Ræ•°æ®é›†ä¸­æŠ½å–200ä¸ªepisodeåˆ›å»ºR2R_smallæ•°æ®é›†
ä¿æŒannotations.jsonå’Œimagesç›®å½•çš„å¯¹åº”å…³ç³»
"""

import json
import os
import random
import shutil
from tqdm import tqdm
import time

def create_r2r_small_dataset():
    """åˆ›å»ºR2R_smallæ•°æ®é›†"""

    # é…ç½®å‚æ•°
    source_dir = "data1/trajectory_data/R2R"
    target_dir = "data1/trajectory_data/R2R_small"
    num_episodes = 200

    print("=" * 60)
    print("åˆ›å»ºR2R_smallæ•°æ®é›†")
    print("=" * 60)
    print(f"æºç›®å½•: {source_dir}")
    print(f"ç›®æ ‡ç›®å½•: {target_dir}")
    print(f"æŠ½å–episodeæ•°é‡: {num_episodes}")
    print()

    # æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    source_annotations = os.path.join(source_dir, "annotations.json")
    source_images = os.path.join(source_dir, "images")

    if not os.path.exists(source_annotations):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æºannotationsæ–‡ä»¶: {source_annotations}")
        return False

    if not os.path.exists(source_images):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æºimagesç›®å½•: {source_images}")
        return False

    # åˆ›å»ºç›®æ ‡ç›®å½•
    os.makedirs(target_dir, exist_ok=True)
    print(f"âœ… åˆ›å»ºç›®æ ‡ç›®å½•: {target_dir}")

    # 1. åŠ è½½annotations
    print("1. åŠ è½½R2R annotations...")
    with open(source_annotations, 'r') as f:
        all_annotations = json.load(f)

    print(f"   ğŸ“Š æ€»episodeæ•°é‡: {len(all_annotations):,}")

    if len(all_annotations) < num_episodes:
        print(f"âš ï¸  è­¦å‘Š: æºæ•°æ®åªæœ‰{len(all_annotations)}ä¸ªepisodeï¼Œå°‘äºè¦æ±‚çš„{num_episodes}ä¸ª")
        num_episodes = len(all_annotations)

    # 2. éšæœºæŠ½å–200ä¸ªepisode
    print("2. éšæœºæŠ½å–episodes...")
    random.seed(42)  # è®¾ç½®éšæœºç§å­ä¿è¯å¯é‡å¤æ€§
    selected_annotations = random.sample(all_annotations, num_episodes)

    print(f"   âœ… æˆåŠŸæŠ½å– {len(selected_annotations):,} ä¸ªepisodes")

    # æ˜¾ç¤ºæŠ½å–çš„episode IDèŒƒå›´
    episode_ids = [annot['id'] for annot in selected_annotations]
    print(f"   ğŸ“‹ Episode IDèŒƒå›´: {min(episode_ids)} - {max(episode_ids)}")
    print(f"   ğŸ“‹ å‰10ä¸ªID: {sorted(episode_ids)[:10]}")

    # 3. æ£€æŸ¥å¯¹åº”çš„imagesç›®å½•
    print("3. æ£€æŸ¥å¯¹åº”çš„imagesç›®å½•...")
    available_images = set()
    missing_images = []

    for annot in selected_annotations:
        video_path = annot['video']  # ä¾‹å¦‚: "images/17DRP5sb8fy_r2r_000577"
        # å»æ‰ "images/" å‰ç¼€ï¼Œå› ä¸ºimagesç›®å½•ç›´æ¥åœ¨source_dirä¸‹
        image_dir_name = video_path.replace("images/", "")
        image_dir_path = os.path.join(source_images, image_dir_name)

        if os.path.exists(image_dir_path):
            available_images.add(image_dir_name)
        else:
            missing_images.append(video_path)

    print(f"   ğŸ“Š æ‰¾åˆ° {len(available_images)} ä¸ªå¯¹åº”çš„imageç›®å½•")

    if missing_images:
        print(f"   âš ï¸  è­¦å‘Š: {len(missing_images)} ä¸ªepisodeç¼ºå°‘å¯¹åº”çš„imagesç›®å½•")
        print(f"   ç¼ºå¤±çš„images (å‰5ä¸ª): {missing_images[:5]}")

    # 4. ä¿å­˜æ–°çš„annotations.json
    print("4. ç”Ÿæˆæ–°çš„annotations.json...")
    target_annotations = os.path.join(target_dir, "annotations.json")

    with open(target_annotations, 'w') as f:
        json.dump(selected_annotations, f, indent=2)

    print(f"   âœ… ä¿å­˜åˆ°: {target_annotations}")
    print(f"   ğŸ“Š æ–‡ä»¶å¤§å°: {os.path.getsize(target_annotations) / 1024:.1f} KB")

    # 5. å¤åˆ¶å¯¹åº”çš„imagesç›®å½•
    print("5. å¤åˆ¶å¯¹åº”çš„imagesç›®å½•...")
    target_images = os.path.join(target_dir, "images")
    os.makedirs(target_images, exist_ok=True)

    copied_count = 0
    for image_dir_name in tqdm(available_images, desc="å¤åˆ¶å›¾ç‰‡ç›®å½•"):
        src_path = os.path.join(source_images, image_dir_name)
        dst_path = os.path.join(target_images, image_dir_name)

        # å¤åˆ¶ç›®å½•
        if os.path.exists(src_path):
            try:
                shutil.copytree(src_path, dst_path, dirs_exist_ok=True)
                copied_count += 1
            except Exception as e:
                print(f"   âŒ å¤åˆ¶å¤±è´¥ {image_dir_name}: {e}")
        else:
            print(f"   âŒ æºç›®å½•ä¸å­˜åœ¨: {src_path}")

    print(f"   âœ… æˆåŠŸå¤åˆ¶ {copied_count} ä¸ªimagesç›®å½•")

    # 6. éªŒè¯æ•°æ®é›†
    print("6. éªŒè¯æ•°æ®é›†...")
    verify_r2r_small_dataset(target_dir)

    # 7. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("æ•°æ®é›†åˆ›å»ºå®Œæˆï¼ç»Ÿè®¡ä¿¡æ¯:")
    print("=" * 60)
    print(f"ğŸ“ ç›®æ ‡ç›®å½•: {target_dir}")
    print(f"ğŸ“„ annotations.json: {len(selected_annotations):,} episodes")
    print(f"ğŸ–¼ï¸  imagesç›®å½•: {copied_count} ä¸ª")

    # ç»Ÿè®¡imagesæ€»å¤§å°
    total_images_size = 0
    for image_dir_name in available_images:
        image_dir_path = os.path.join(target_images, image_dir_name)
        if os.path.exists(image_dir_path):
            for root, dirs, files in os.walk(image_dir_path):
                for file in files:
                    file_path = os.path.join(root, file)
                    if os.path.exists(file_path):
                        total_images_size += os.path.getsize(file_path)

    print(f"ğŸ’¾ imagesæ€»å¤§å°: {total_images_size / (1024*1024):.1f} MB")

    # éªŒè¯å¯¹åº”å…³ç³»
    print(f"\nğŸ” éªŒè¯å‰10ä¸ªepisodesçš„å¯¹åº”å…³ç³»:")
    for i, annot in enumerate(selected_annotations[:10]):
        video_path = annot['video']
        image_dir_name = video_path.replace("images/", "")
        expected_path = os.path.join(target_images, image_dir_name)

        if os.path.exists(expected_path):
            # æ£€æŸ¥rgbç›®å½•æ˜¯å¦å­˜åœ¨
            rgb_dir = os.path.join(expected_path, "rgb")
            if os.path.exists(rgb_dir):
                rgb_count = len(os.listdir(rgb_dir))
                print(f"   âœ… Episode {annot['id']:6d}: {image_dir_name} ({rgb_count} RGB images)")
            else:
                print(f"   âš ï¸  Episode {annot['id']:6d}: {image_dir_name} (ç¼ºå°‘rgbç›®å½•)")
        else:
            print(f"   âŒ Episode {annot['id']:6d}: {image_dir_name} (ç¼ºå¤±)")

    print(f"\nğŸ‰ R2R_smallæ•°æ®é›†åˆ›å»ºæˆåŠŸï¼")
    print(f"ğŸ“ ä½ç½®: {target_dir}")
    print(f"ğŸ“ ç°åœ¨å¯ä»¥ç”¨äºstreamvln_train.shå¿«é€ŸéªŒè¯")

    # 7. ä¿®æ”¹é…ç½®æ–‡ä»¶è·¯å¾„çš„å»ºè®®
    print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print(f"   ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„æ•°æ®è·¯å¾„æŒ‡å‘: {target_dir}")
    print(f"   ä¾‹å¦‚: data_path: {target_dir}/annotations.json")

    return True

def verify_r2r_small_dataset(target_dir):
    """éªŒè¯R2R_smallæ•°æ®é›†çš„å®Œæ•´æ€§"""
    print("   ğŸ” éªŒè¯æ•°æ®é›†å®Œæ•´æ€§...")

    annotations_file = os.path.join(target_dir, "annotations.json")
    images_dir = os.path.join(target_dir, "images")

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(annotations_file):
        print(f"   âŒ annotations.jsonä¸å­˜åœ¨")
        return False

    if not os.path.exists(images_dir):
        print(f"   âŒ imagesç›®å½•ä¸å­˜åœ¨")
        return False

    # æ£€æŸ¥annotationsæ ¼å¼
    try:
        with open(annotations_file, 'r') as f:
            annotations = json.load(f)

        print(f"   âœ… annotations.jsonæ ¼å¼æ­£ç¡®ï¼ŒåŒ…å«{len(annotations)}ä¸ªepisodes")

        # æ£€æŸ¥å¿…è¦å­—æ®µ
        required_fields = ['id', 'video', 'instructions', 'actions']
        missing_fields_count = 0

        for i, annot in enumerate(annotations[:5]):  # æ£€æŸ¥å‰5ä¸ª
            for field in required_fields:
                if field not in annot:
                    missing_fields_count += 1
                    print(f"   âŒ Episode {i} ç¼ºå°‘å­—æ®µ: {field}")

        if missing_fields_count == 0:
            print("   âœ… æ£€æŸ¥çš„episodeséƒ½åŒ…å«å¿…è¦å­—æ®µ")

    except json.JSONDecodeError as e:
        print(f"   âŒ annotations.jsonæ ¼å¼é”™è¯¯: {e}")
        return False

    # æ£€æŸ¥imagesç›®å½•
    image_dirs = [d for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, d))]
    print(f"   âœ… imagesç›®å½•åŒ…å«{len(image_dirs)}ä¸ªå­ç›®å½•")

    # æ£€æŸ¥å‰å‡ ä¸ªimageç›®å½•æ˜¯å¦åŒ…å«rgbå­ç›®å½•
    rgb_dirs_count = 0
    for image_dir in image_dirs[:10]:
        rgb_path = os.path.join(images_dir, image_dir, "rgb")
        if os.path.exists(rgb_path):
            rgb_dirs_count += 1

    print(f"   âœ… å‰10ä¸ªimageç›®å½•ä¸­æœ‰{rgb_dirs_count}ä¸ªåŒ…å«rgbå­ç›®å½•")

    print("   âœ… æ•°æ®é›†éªŒè¯é€šè¿‡")
    return True

if __name__ == "__main__":
    start_time = time.time()
    success = create_r2r_small_dataset()
    end_time = time.time()

    if success:
        print(f"\nğŸ‰ æˆåŠŸåˆ›å»ºR2R_smallæ•°æ®é›†ï¼è€—æ—¶: {end_time - start_time:.1f}ç§’")
    else:
        print(f"\nâŒ åˆ›å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")